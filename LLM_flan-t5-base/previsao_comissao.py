# previsao_comissao.py

# Previs√£o de Comiss√£o com Modelos Estat√≠sticos e LLM Local

"""
Este script realiza an√°lises preditivas de valor de comiss√£o a partir de uma base fict√≠cia de ap√≥lices,
utilizando modelos estat√≠sticos (Regress√£o Linear e Random Forest) e uma LLM local (FLAN-T5) para explica√ß√µes.

Etapas:
1. Carregamento e pr√©-processamento dos dados
2. Modelagem estat√≠stica com Regress√£o Linear e Random Forest (com divis√£o treino/teste)
3. Gera√ß√£o de previs√µes para os pr√≥ximos 30 dias
4. Gera√ß√£o de gr√°ficos de hist√≥rico (√∫ltimos 12 meses) + previs√£o
5. Gera√ß√£o de aba explicativa com m√©tricas estat√≠sticas de performance do modelo (com LLM)
6. Salvamento dos resultados em arquivo Excel

Requisitos:
- pip install pandas scikit-learn transformers torch openpyxl matplotlib
"""

# === CONFIGURA√á√ÉO INICIAL =====================================================
# Define o diret√≥rio de entrada onde os arquivos de dados (Excel) est√£o localizados.
INPUT_DIR = r'INSERIR_CAMINHO_AQUI' # Substitua pelo caminho real dos arquivos de entrada.
# Define o diret√≥rio de sa√≠da onde os resultados (Excel e gr√°ficos) ser√£o salvos.
OUTPUT_DIR = r'INSERIR_CAMINHO_AQUI' # Substitua pelo caminho real do diret√≥rio de sa√≠da.
# Nome do modelo de Linguagem Grande (LLM) a ser carregado para gerar explica√ß√µes.
MODEL_NAME = "google/flan-t5-base"

# =============================================================================
# Importa m√≥dulos e bibliotecas necess√°rios para o script.
import os # Para interagir com o sistema operacional (caminhos, diret√≥rios).
import sys # Para interagir com o interpretador Python.
import time # Para medir o tempo de execu√ß√£o.
import getpass # Para obter o nome de usu√°rio do sistema.
import platform # Para obter informa√ß√µes sobre o sistema operacional.
import warnings # Para gerenciar avisos.
from glob import glob # Para encontrar arquivos que correspondem a um padr√£o espec√≠fico.
from datetime import datetime, timedelta # Para manipula√ß√£o de datas e tempo.
import argparse # Para lidar com argumentos de linha de comando.

import pandas as pd # Para manipula√ß√£o e an√°lise de dados tabulares (DataFrames).
import numpy as np # Para opera√ß√µes num√©ricas e arrays.
from sklearn.model_selection import train_test_split # Para dividir dados em conjuntos de treino e teste.
from sklearn.linear_model import LinearRegression # Modelo de Regress√£o Linear.
from sklearn.ensemble import RandomForestRegressor # Modelo de Random Forest para regress√£o.
# IMPORTANTE: A linha abaixo foi ajustada para incluir 'root_mean_squared_error'
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, root_mean_squared_error # M√©tricas de avalia√ß√£o de modelos.
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM # Para carregar o tokenizer e o modelo LLM.
import torch # Biblioteca PyTorch, usada pelo Hugging Face Transformers para LLM.
import matplotlib.pyplot as plt # Para cria√ß√£o de gr√°ficos.
# Importa√ß√µes adicionais para formata√ß√£o Excel
from openpyxl import load_workbook
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils import get_column_letter

# Configura√ß√µes para o Matplotlib para padronizar a apar√™ncia dos gr√°ficos.
plt.style.use('seaborn-v0_8-darkgrid') # Define um estilo visual para os gr√°ficos.
plt.rcParams['figure.figsize'] = (12, 6) # Define o tamanho padr√£o das figuras (largura, altura).
plt.rcParams['lines.linewidth'] = 2 # Define a largura padr√£o das linhas nos gr√°ficos.
plt.rcParams['font.size'] = 12 # Define o tamanho da fonte padr√£o para o texto nos gr√°ficos.

# Ignora avisos espec√≠ficos da biblioteca scikit-learn para evitar polui√ß√£o no console.
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn")

# Configura o parser de argumentos de linha de comando.
parser = argparse.ArgumentParser(add_help=False) # 'add_help=False' evita que o parser adicione a op√ß√£o -h/--help automaticamente.
# Adiciona o argumento '-i' ou '--input' para especificar o diret√≥rio de entrada.
parser.add_argument("-i", "--input", dest="cli_input")
# Adiciona o argumento '-o' ou '--output' para especificar o diret√≥rio de sa√≠da.
parser.add_argument("-o", "--output", dest="cli_output")
args, _ = parser.parse_known_args() # Analisa os argumentos fornecidos na linha de comando.

# Sobrescreve INPUT_DIR e OUTPUT_DIR se forem fornecidos via linha de comando.
if args.cli_input:
    INPUT_DIR = args.cli_input
if args.cli_output:
    OUTPUT_DIR = args.cli_output

# Verifica se o diret√≥rio de entrada existe; caso contr√°rio, levanta um erro.
if not os.path.isdir(INPUT_DIR):
    raise FileNotFoundError(f"Pasta de entrada n√£o encontrada: {INPUT_DIR}")
# Cria o diret√≥rio de sa√≠da se ele n√£o existir (exist_ok=True evita erro se j√° existir).
os.makedirs(OUTPUT_DIR, exist_ok=True)
# Define o caminho para o subdiret√≥rio onde os gr√°ficos ser√£o salvos.
GRAFICOS_DIR = os.path.join(OUTPUT_DIR, "graficos")
# Cria o diret√≥rio para gr√°ficos se ele n√£o existir.
os.makedirs(GRAFICOS_DIR, exist_ok=True)

# Imprime informa√ß√µes sobre o ambiente de execu√ß√£o e os diret√≥rios.
print("\nüßë Usu√°rio:", getpass.getuser()) # Mostra o nome do usu√°rio logado.
print("üíª M√°quina:", platform.node()) # Mostra o nome da m√°quina.
print("üêç Python :", sys.version.split()[0]) # Mostra a vers√£o do Python.
print("üóïÔ∏è In√≠cio ¬†:", datetime.now().strftime("%Y-%m-%d %H:%M:%S")) # Mostra a data e hora de in√≠cio.
print("\nInput :", INPUT_DIR) # Confirma o diret√≥rio de entrada.
print("Output:", OUTPUT_DIR) # Confirma o diret√≥rio de sa√≠da.
print("="*60, "\n") # Imprime uma linha de separa√ß√£o.

# === 1. Carregar e Pr√©-processar Dados =======================================
print("üîç Varredura de .xlsx‚Ä¶")
# Procura por todos os arquivos .xlsx no diret√≥rio de entrada.
arquivos_xlsx = glob(os.path.join(INPUT_DIR, "*.xlsx"))
# Se nenhum arquivo .xlsx for encontrado, levanta um erro.
if not arquivos_xlsx:
    raise FileNotFoundError("Nenhum .xlsx encontrado na pasta de entrada.")
# Imprime o nome de cada arquivo .xlsx encontrado.
for arq in arquivos_xlsx:
    print(" ¬† ‚Ä¢", os.path.basename(arq))

# L√™ cada arquivo Excel e armazena seus DataFrames em uma lista.
lista_df = [pd.read_excel(arq) for arq in arquivos_xlsx]
# Concatena todos os DataFrames em um √∫nico DataFrame.
df_original = pd.concat(lista_df, ignore_index=True)

# Define as colunas que s√£o obrigat√≥rias no DataFrame.
colunas_obrigatorias = ["Data de Emiss√£o", "Valor Comiss√£o", "Seguradora", "Produto"]
# Verifica se todas as colunas obrigat√≥rias est√£o presentes. Se n√£o, levanta um erro.
if not all(col in df_original.columns for col in colunas_obrigatorias):
    raise ValueError(f"As colunas {colunas_obrigatorias} s√£o obrigat√≥rias.")

# Converte a coluna 'Data de Emiss√£o' para o tipo datetime.
df_original["Data de Emiss√£o"] = pd.to_datetime(df_original["Data de Emiss√£o"])
# Converte as colunas 'Seguradora' e 'Produto' para o tipo string.
df_original["Seguradora"] = df_original["Seguradora"].astype(str)
df_original["Produto"] = df_original["Produto"].astype(str)
# Converte 'Valor Comiss√£o' para num√©rico, tratando erros (valores inv√°lidos viram NaN).
df_original["Valor Comiss√£o"] = pd.to_numeric(df_original["Valor Comiss√£o"], errors='coerce')
# Remover as linhas onde 'Valor Comiss√£o' √© NaN (nulo) ap√≥s a convers√£o.
df_original.dropna(subset=["Valor Comiss√£o"], inplace=True)

print(f"‚úÖ Dados carregados. Total de {len(df_original)} registros.")

# === Carregar LLM para Gera√ß√£o de Explica√ß√µes ================================
print(f"üß† Carregando LLM ({MODEL_NAME}) para gera√ß√£o de explica√ß√µes...")
# Carrega o tokenizer (respons√°vel por converter texto em tokens que o modelo entende) do modelo especificado.
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
# Carrega o modelo de Linguagem Grande (LLM) pr√©-treinado.
model_llm = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)
# Verifica se uma GPU (CUDA) est√° dispon√≠vel e move o modelo para a GPU, se sim, para acelerar o processamento.
if torch.cuda.is_available():
    model_llm.to('cuda')
    print(" ¬† ‚Ä¢ LLM carregada para GPU.")
else:
    print(" ¬† ‚Ä¢ LLM carregada para CPU.")

# Define uma fun√ß√£o para gerar explica√ß√µes usando a LLM.
def generate_llm_explanation(prompt_text):
    # Tokeniza o texto de entrada (prompt), convertendo-o em tensores para o modelo.
    # 'max_length' e 'truncation' garantem que o texto n√£o exceda o limite do modelo.
    inputs = tokenizer(prompt_text, return_tensors="pt", max_length=512, truncation=True)
    # Se a GPU estiver dispon√≠vel, move os inputs para a GPU.
    if torch.cuda.is_available():
        inputs = {k: v.to('cuda') for k, v in inputs.items()}
    # Desativa o c√°lculo de gradientes para economizar mem√≥ria e acelerar a infer√™ncia.
    with torch.no_grad():
        # Gera a sa√≠da do modelo com base nos inputs.
        outputs = model_llm.generate(
            **inputs,
            max_new_tokens=100, # Limita o n√∫mero de novos tokens gerados na resposta.
            num_beams=5, # Usa busca em feixe para gerar respostas mais coerentes.
            early_stopping=True # Para a gera√ß√£o se o modelo determinar que j√° encontrou uma boa resposta.
        )
    # Decodifica os tokens gerados de volta para texto leg√≠vel, ignorando tokens especiais.
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# === 2. Modelagem e Previs√µes para os Pr√≥ximos 30 Dias =======================
print("\nü§ñ Gerando previs√µes estat√≠sticas para os pr√≥ximos 30 dias‚Ä¶")
resultados = [] # Lista para armazenar os resultados das previs√µes.
metricas_modelos = [] # Lista para armazenar as m√©tricas de desempenho dos modelos.
# CORRE√á√ÉO: data_inicio_exec movida para fora do loop para capturar o tempo total do processo
data_inicio_exec = time.time() # Registra o tempo de in√≠cio para calcular a dura√ß√£o.

# Itera sobre cada grupo √∫nico de "Seguradora" e "Produto" no DataFrame original.
for (seg, prod), grupo in df_original.groupby(["Seguradora", "Produto"]):
    # Pula grupos com menos de 2 registros, pois n√£o √© poss√≠vel treinar um modelo com t√£o poucos dados.
    if len(grupo) < 2:
        print(f" ¬† ‚Ä¢ Pulando {seg} - {prod}: Poucos dados para modelagem ({len(grupo)} registros).")
        continue

    # Cria uma c√≥pia do grupo e o ordena pela 'Data de Emiss√£o'.
    grupo = grupo.sort_values("Data de Emiss√£o").copy()
    # Adiciona uma coluna 'Dias' representando o n√∫mero de dias desde a primeira emiss√£o do grupo.
    grupo["Dias"] = (grupo["Data de Emiss√£o"] - grupo["Data de Emiss√£o"].min()).dt.days

    # Define as features (vari√°veis independentes) e o target (vari√°vel dependente).
    X_full = grupo[["Dias"]] # 'Dias' √© a feature.
    y_full = grupo["Valor Comiss√£o"] # 'Valor Comiss√£o' √© o target.

    # Divis√£o treino/teste para avalia√ß√£o do modelo
    # Divide os dados, usando 80% para treino e 20% para teste, mantendo a ordem temporal.
    split_point = int(len(grupo) * 0.8)
    X_train, X_test = X_full.iloc[:split_point], X_full.iloc[split_point:]
    y_train, y_test = y_full.iloc[:split_point], y_full.iloc[split_point:]

    # Pula se a divis√£o resultar em conjuntos de treino ou teste vazios.
    if len(X_train) == 0 or len(X_test) == 0:
        print(f" ¬† ‚Ä¢ Pulando {seg} - {prod}: Divis√£o treino/teste resultou em conjuntos vazios.")
        continue

    # Instancia os modelos de regress√£o.
    lr = LinearRegression() # Regress√£o Linear.
    rf = RandomForestRegressor(random_state=42) # Random Forest Regressor com uma semente para reprodutibilidade.

    try:
        # Treina os modelos com os dados de treino.
        lr.fit(X_train, y_train)
        rf.fit(X_train, y_train)

        # Avalia os modelos no conjunto de teste.
        y_pred_lr_test = lr.predict(X_test) # Previs√µes do modelo de Regress√£o Linear.
        y_pred_rf_test = rf.predict(X_test) # Previs√µes do modelo de Random Forest.
        # Calcula a m√©dia das previs√µes de ambos os modelos para uma previs√£o combinada.
        y_pred_avg_test = (y_pred_lr_test + y_pred_rf_test) / 2

        # Calcula as m√©tricas de erro para a previs√£o combinada.
        mae_test = mean_absolute_error(y_test, y_pred_avg_test) # Erro Absoluto M√©dio.
        # AJUSTE: Usando root_mean_squared_error diretamente (para scikit-learn >= 1.2)
        rmse_test = root_mean_squared_error(y_test, y_pred_avg_test) # Raiz do Erro Quadr√°tico M√©dio.
        r2_test = r2_score(y_test, y_pred_avg_test) # Coeficiente de Determina√ß√£o (R¬≤).

        # Armazena as m√©tricas de desempenho do modelo.
        metricas_modelos.append({
            "Seguradora": seg,
            "Produto": prod,
            "MAE (Modelo)": round(mae_test, 2),
            "RMSE (Modelo)": round(rmse_test, 2),
            "R¬≤ (Modelo)": round(r2_test, 4)
        })

        # Previs√µes para os pr√≥ximos 30 dias (usando o modelo treinado com TODOS os dados hist√≥ricos)
        # √â importante retreinar com todos os dados para a previs√£o futura mais precisa
        lr_final = LinearRegression().fit(X_full, y_full) # Retreina LR com todos os dados.
        rf_final = RandomForestRegressor(random_state=42).fit(X_full, y_full) # Retreina RF com todos os dados.

        ultima_data_historica = grupo["Data de Emiss√£o"].max() # √öltima data de emiss√£o no hist√≥rico.
        data_min_historica = grupo["Data de Emiss√£o"].min() # Primeira data de emiss√£o no hist√≥rico.

        # Loop para prever os pr√≥ximos 30 dias.
        for i in range(1, 31):
            data_prevista = ultima_data_historica + timedelta(days=i) # Calcula a data futura.
            dias_futuros = (data_prevista - data_min_historica).days # Calcula os dias desde a data m√≠nima hist√≥rica.
            dias_df = pd.DataFrame({"Dias": [dias_futuros]}) # Cria um DataFrame com os dias futuros para previs√£o.

            prev_lr = lr_final.predict(dias_df)[0] # Previs√£o da Regress√£o Linear.
            prev_rf = rf_final.predict(dias_df)[0] # Previs√£o do Random Forest.
            # Calcula a m√©dia das previs√µes, garantindo que o valor da comiss√£o n√£o seja negativo.
            valor_estimado = max(0, (prev_lr + prev_rf) / 2)

            # Adiciona os resultados da previs√£o √† lista.
            resultados.append({
                "Seguradora": seg,
                "Produto": prod,
                "Data": data_prevista.date(), # Armazena apenas a data.
                "Previs√£o Comiss√£o": valor_estimado # Armazena como float para c√°lculos futuros.
            })
    # Captura e imprime quaisquer erros que ocorram durante a modelagem.
    except Exception as e:
        print(f" ¬† ‚Ä¢ Erro ao modelar {seg} - {prod}: {e}")
        # Adiciona m√©tricas nulas caso ocorra um erro na modelagem.
        metricas_modelos.append({
            "Seguradora": seg, "Produto": prod,
            "MAE (Modelo)": None, "RMSE (Modelo)": None, "R¬≤ (Modelo)": None
        })

# Converte as listas de resultados e m√©tricas em DataFrames.
df_resultados = pd.DataFrame(resultados)
df_metricas_modelos = pd.DataFrame(metricas_modelos)

# === 3. Salvar Excel de Resultados ===========================================
print("\nüìÑ Salvando Excel de previs√µes e m√©tricas‚Ä¶")

excel_saida = os.path.join(OUTPUT_DIR, "previsao_llm_30dias.xlsx") # Define o caminho do arquivo Excel de sa√≠da.

# N√£o formatamos df_resultados para string aqui, ele ser√° salvo como n√∫mero/data e formatado via openpyxl
if df_resultados.empty:
    print("‚ö†Ô∏è Aten√ß√£o: DataFrame de resultados vazio. A aba 'Previsao_30_Dias' ser√° gerada vazia.")
    df_resultados_formatado = pd.DataFrame(columns=["Seguradora", "Produto", "Data", "Previs√£o Comiss√£o"]) # Cria um DF vazio com as colunas esperadas
else:
    # Usaremos df_resultados diretamente, sem df_resultados_formatado para manter tipos num√©ricos
    df_resultados_formatado = df_resultados.copy() # Criamos uma c√≥pia s√≥ para consist√™ncia com o nome da vari√°vel se voc√™ preferir

# Usa pd.ExcelWriter para criar e salvar o arquivo Excel.
with pd.ExcelWriter(excel_saida, engine="openpyxl") as writer:
    # Salva o DataFrame de resultados na aba "Previsao_30_Dias".
    df_resultados_formatado.to_excel(writer, sheet_name="Previsao_30_Dias", index=False)
    # A aba de m√©tricas ser√° adicionada posteriormente com as explica√ß√µes da LLM.

# === 4. Gera√ß√£o de Gr√°ficos ==================================================
print("\nüìä Gerando gr√°ficos por Seguradora e Produto‚Ä¶")

# Itera sobre cada grupo de "Seguradora" e "Produto" no DataFrame de resultados de previs√£o.
# Adicionada uma verifica√ß√£o de 'df_resultados.empty' para evitar erro se n√£o houver previs√µes
if not df_resultados.empty:
    for (seg, prod), grupo_prev in df_resultados.groupby(["Seguradora", "Produto"]):
        historico = df_original[(df_original["Seguradora"] == seg) & (df_original["Produto"] == prod)].copy()
        historico_grouped = historico.groupby("Data de Emiss√£o")["Valor Comiss√£o"].sum().reset_index()

        # Filtrar hist√≥rico para os √∫ltimos 12 meses
        # Considera 12m a partir da data atual de execu√ß√£o, para o hist√≥rico
        corte_data = datetime.now() - pd.DateOffset(months=12)
        historico_grouped = historico_grouped[historico_grouped["Data de Emiss√£o"] >= corte_data]

        plt.figure(figsize=(12, 6))
        plt.plot(historico_grouped["Data de Emiss√£o"], historico_grouped["Valor Comiss√£o"],
                 label="Hist√≥rico (√∫lt. 12m)", marker="o", markersize=4, color='blue')
        plt.plot(grupo_prev["Data"], grupo_prev["Previs√£o Comiss√£o"],
                 label="Previs√£o (30d)", linestyle="--", marker="x", markersize=4, color='red')

        plt.title(f"Previs√£o de Comiss√£o: {seg} ‚Äì {prod}", fontsize=16)
        plt.xlabel("Data", fontsize=14)
        plt.ylabel("Comiss√£o (R$)", fontsize=14)
        plt.legend(fontsize=12)
        plt.grid(True, linestyle='--', alpha=0.7)
        plt.xticks(rotation=45)
        plt.tight_layout()

        nome_fig = f"{seg}_{prod}.png".replace(" ", "_").replace("/", "_").replace("\\", "_")
        plt.savefig(os.path.join(GRAFICOS_DIR, nome_fig))
        plt.close()
    print(f"‚úÖ Gr√°ficos gerados e salvos em: {GRAFICOS_DIR}")
else:
    print("üö´ N√£o h√° dados de previs√£o para gerar gr√°ficos. O DataFrame de resultados est√° vazio.")

# === 5. Gera√ß√£o de Explica√ß√µes Estat√≠sticas com LLM ==========================
print("\nüß† Gerando aba de explica√ß√µes estat√≠sticas com LLM...")

explicacoes = [] # Lista para armazenar as explica√ß√µes geradas pela LLM.
# Itera sobre cada linha do DataFrame de m√©tricas do modelo.
# Adicionada uma verifica√ß√£o de 'df_metricas_modelos.empty' para evitar erro se n√£o houver m√©tricas
if not df_metricas_modelos.empty:
    for index, row in df_metricas_modelos.iterrows():
        seg = row["Seguradora"]
        prod = row["Produto"]
        mae = row["MAE (Modelo)"]
        rmse = row["RMSE (Modelo)"]
        r2 = row["R¬≤ (Modelo)"]

        interpreta√ß√£o_llm = "N√£o foi poss√≠vel gerar uma interpreta√ß√£o." # Mensagem padr√£o caso n√£o haja interpreta√ß√£o.

        # Gera a interpreta√ß√£o apenas se o R¬≤ n√£o for nulo (ou seja, se o modelo foi treinado com sucesso).
        if pd.notna(r2):
            # Constr√≥i o prompt para a LLM, incluindo as m√©tricas do modelo.
            prompt = (
                f"Considere as seguintes m√©tricas de um modelo de previs√£o de comiss√£o "
                f"para a seguradora '{seg}' e produto '{prod}':\n"
                f"- Erro Absoluto M√©dio (MAE): R${mae:,.2f}\n"
                f"- Raiz do Erro Quadr√°tico M√©dio (RMSE): R${rmse:,.2f}\n"
                f"- Coeficiente de Determina√ß√£o (R¬≤): {r2:.4f}\n\n"
                f"Forne√ßa uma breve interpreta√ß√£o dessas m√©tricas, explicando o que elas significam "
                f"em termos da capacidade do modelo de prever o valor de comiss√£o."
            )
            # Chama a fun√ß√£o para gerar a explica√ß√£o usando a LLM.
            interpreta√ß√£o_llm = generate_llm_explanation(prompt)

        # Adiciona as m√©tricas e a interpreta√ß√£o da LLM √† lista de explica√ß√µes.
        explicacoes.append({
            "Seguradora": seg,
            "Produto": prod,
            "MAE (Modelo)": mae,
            "RMSE (Modelo)": rmse,
            "R¬≤ (Modelo)": r2,
            "Interpreta√ß√£o da LLM": interpreta√ß√£o_llm
        })

    # Converte a lista de explica√ß√µes em um DataFrame.
    df_exp = pd.DataFrame(explicacoes)

    # Salva o DataFrame de explica√ß√µes em uma nova aba no arquivo Excel existente.
    print("üìÑ Salvando aba 'Resumo_Explicativo' no Excel...")
    # Abre o arquivo Excel em modo de anexar ('a') e substitui a aba se j√° existir.
    with pd.ExcelWriter(excel_saida, engine="openpyxl", mode="a", if_sheet_exists="replace") as writer:
        df_exp.to_excel(writer, sheet_name="Resumo_Explicativo", index=False)
else:
    print("üö´ N√£o h√° m√©tricas de modelo para gerar explica√ß√µes. A aba 'Resumo_Explicativo' n√£o ser√° criada ou ser√° vazia.")

# === 6. Aplica√ß√£o de Formata√ß√£o Final no Excel (P√ìS-SALVAMENTO) ==============
print("\nüìù Aplicando formata√ß√£o final ao arquivo Excel...")
try:
    wb = load_workbook(excel_saida)

    # --- Formata√ß√£o para a aba 'Previsao_30_Dias' ---
    if "Previsao_30_Dias" in wb.sheetnames:
        ws_previsao = wb["Previsao_30_Dias"]
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="4CAF50", end_color="4CAF50", fill_type="solid") # Verde
        thin_border = Border(left=Side(style='thin'), right=Side(style='thin'), top=Side(style='thin'), bottom=Side(style='thin'))

        for col_idx, cell in enumerate(ws_previsao[1]): # Itera pelas c√©lulas do cabe√ßalho (primeira linha)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal='center', vertical='center')
            cell.border = thin_border
            # Auto-ajuste de largura da coluna
            column_letter = get_column_letter(col_idx + 1)
            ws_previsao.column_dimensions[column_letter].width = max(len(str(cell.value)), 15)

        # Formatar coluna 'Data' como Data (coluna C, √≠ndice 2)
        # Nota: iter_rows min_col e max_col s√£o baseados em 1, n√£o 0
        for row in ws_previsao.iter_rows(min_row=2, min_col=3, max_col=3):
            for cell in row:
                cell.number_format = 'DD/MM/YYYY' # Formato de data
                cell.alignment = Alignment(horizontal='center')
                cell.border = thin_border

        # AJUSTE FEITO AQUI: Formatar coluna 'Previs√£o Comiss√£o' como n√∫mero com 2 casas decimais
        for row in ws_previsao.iter_rows(min_row=2, min_col=4, max_col=4): # Coluna 'Previs√£o Comiss√£o' √© a 4¬™ (D)
            for cell in row:
                cell.number_format = '#,##0.00' # Formato num√©rico com duas casas decimais
                cell.alignment = Alignment(horizontal='right')
                cell.border = thin_border

    # --- Formata√ß√£o para a aba 'Resumo_Explicativo' ---
    if "Resumo_Explicativo" in wb.sheetnames:
        ws_resumo = wb["Resumo_Explicativo"]
        # Aplica a mesma formata√ß√£o de cabe√ßalho
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="4CAF50", end_color="4CAF50", fill_type="solid")
        thin_border = Border(left=Side(style='thin'), right=Side(style='thin'), top=Side(style='thin'), bottom=Side(style='thin'))

        for col_idx, cell in enumerate(ws_resumo[1]):
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal='center', vertical='center')
            cell.border = thin_border
            column_letter = get_column_letter(col_idx + 1)
            ws_resumo.column_dimensions[column_letter].width = max(len(str(cell.value)), 20) # Ajuste a largura conforme necess√°rio

        # Ajuste de largura espec√≠fico para a coluna de interpreta√ß√£o
        # Assumindo que "Interpreta√ß√£o da LLM" √© a √∫ltima coluna
        if ws_resumo.max_column >= 5: # Verifica se a coluna existe
            ws_resumo.column_dimensions[get_column_letter(5)].width = 80 # Coluna E, ajustar a largura

    wb.save(excel_saida)
    print("‚úÖ Formata√ß√£o Excel aplicada com sucesso!")

except Exception as e:
    print(f"‚ö†Ô∏è Erro ao aplicar formata√ß√£o final ao Excel: {e}")


# === FINAL ===================================================================
# Mensagens de conclus√£o e resumo do processamento.
print("\n‚úÖ PROCESSAMENTO CONCLU√çDO: Previs√£o de Comiss√£o")
print("üìÅ Excel gerado :", excel_saida) # Caminho do arquivo Excel final.
print("üóÉÔ∏è Gr√°ficos em  :", GRAFICOS_DIR) # Caminho do diret√≥rio de gr√°ficos.
print("‚è±Ô∏è Tempo total  : {:.2f}s".format(time.time() - data_inicio_exec)) # Tempo total de execu√ß√£o.
print("="*60, "\n") # Linha de separa√ß√£o final.